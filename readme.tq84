
loadModel (index.html)
  -> initialize (model.js)
     -> loadModel (model.js)

        -> loadParameters()
           Reads params_gpt.json
           and calculates some other values from it

        -> loadEmbeddings()
           Fetches transformer.wte.weight_gpt.bin
           returns { embeddingsBuffers, deEmbeddingsBuffers}

        -> loadPositionalEmbeddings()
        -> loadLayers()
        -> loadFinalLayerNorm()

        loadModel returns
          {
             output: {
               layer_buffers:       {},
               embeddingsBuffers:   {},
               deEmbeddingsBuffers: {},
               posEmbdBuffer:       {},
               normGammaBuffer:     {},
               normBetaBuffer       {}
             }
             params: {
             }
          }
         
        -> loadLayers (model.js)
            -> loadLayer (model.js)
               -> fetchAndInitTensor (model.js)

------------------------------

  fetchBin()
     async function fetchBin(url) {
       const response = await fetch(url);
       const buffer = await response.arrayBuffer();
       return new Float32Array(buffer);
     }

-----------------------------

Tokenizer type BPE = Byte Pair Encoding

this project knows two tokenizer types:
  - char (only used for the shakespeare model)
  - bpe

Operations (see globals.js)
  const FastMatMulBlock = new FastMatMulBlockClass();
  const AttentionBlock  = new AttentionBlockClass();
  const ResidualBlock   = new ResidualBlockClass();
  const EmbedBlock      = new EmbedBlockClass();
  const DeEmbedBlock    = new DeEmbedBlockClass();
  const GeluBlock       = new GeluBlockClass();
  const LayerNormBlock  = new LayerNormBlockClass();
  const SoftmaxBlock    = new SoftmaxBlockClass();

Some relationsships of parameters in loadParameters() (model.js)

What is minBufferOffset (=1) used for?


{ Files in the weights/xyz folder

  transformer.wte.weight_gpt.bin          (loaded in loadEmbeddings() into variable embeddingsWeights )  - wte = Word token embeddings  - size = 38597376 | used to map each token in the input sequence to a high-dimensional vector representatio

}

{ Function transpose (globals.js)

  Translate from row major to column major and vice versa

  transpose([0,2,4 , 1,3,5 ], 2, 3)
  => Float32Array(6)Â [0, 1, 2, 3, 4, 5]

  transpose([0,1 , 2,3 , 4,5], 3, 2)
  => Float32Array(6) [0, 2, 4, 1, 3, 5]


}
